# bleurt_eval

Evaluation of titles generated by Ukrainian model for GPT2 using BLEURT.

## Experiment setup:
 - Bleurt installed from master (at commit `cebe7e6f996b40910cfaa520a63db47807e3bf5c`)
 - using BLEURT-20 model
 
## bert_score reported on the same data.
bert_score version 0.3.13
two multilang models:
 - xlm-roberta-large, ranked 48
 - bert-base-multilingual-cased, ranked 81
 
 ```bash
 $ time bert-score -r expected.txt -c predicted.txt -m xlm-roberta-large
 ```
 
`xlm-roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.26.1)_fast-tokenizer P: 0.916548 R: 0.909308 F1: 0.912751`

 ```bash
 $ time bert-score -r expected.txt -c predicted.txt -m bert-base-multilingual-cased
 ```
 
`bert-base-multilingual-cased_L9_no-idf_version=0.3.12(hug_trans=4.26.1)_fast-tokenizer P: 0.792963 R: 0.780369 F1: 0.786095`
